{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG app with Elasticsearch & OpenAI\n",
    "1. Elasticsearch is used to index FAQ documents from 3 DataTalks.Club courses\n",
    "1. queries to Elasticsearch retrieve documents\n",
    "1. retrieved documents are used to build a prompt\n",
    "1. OpenAI API is used to generate a response to the user's question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from elasticsearch import Elasticsearch\n",
    "from tqdm.auto import tqdm\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('.envrc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### created a volume with \n",
    "`> docker volume create faq_elasticsearch_data`  \n",
    "\n",
    "#### now I can start the container with the attached volume to load up the indexed documents\n",
    "```bash\n",
    "docker run -it --rm --name elasticsearch \\ \n",
    "    -p 9200:9200 -p 9300:9300 \\\n",
    "    -e \"discovery.type=single-node\" \\\n",
    "    -e \"xpack.security.enabled=false\" \\\n",
    "    -v faq_elasticsearch_data:/usr/share/faq/elasticsearch/data \\\n",
    "    docker.elastic.co/elasticsearch/elasticsearch:8.4.3\n",
    "```\n",
    "with the volumne attached, any previously indexed docs will be persisted & load up each time the container is started  \n",
    "the following cell is commented out because the documents have already been indexed\n",
    "\n",
    "run shell script in terminal to start container:  \n",
    "`> llm-zoomcamp/elasticsearch/scripts/run_elasticsearch_w_volume.sh`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_file_path = './data/documents.json'\n",
    "\n",
    "# with open(doc_file_path, 'rt') as f_in:\n",
    "#     documents_file = json.load(f_in)\n",
    "\n",
    "# documents = []\n",
    "\n",
    "# for course in documents_file:\n",
    "#     course_name = course['course']\n",
    "\n",
    "#     for doc in course['documents']:\n",
    "#         doc['course'] = course_name\n",
    "#         documents.append(doc)\n",
    "\n",
    "# print(documents[0])\n",
    "\n",
    "# index_settings = {\n",
    "#     \"settings\": {\n",
    "#         \"number_of_shards\": 1,\n",
    "#         \"number_of_replicas\": 0\n",
    "#     },\n",
    "#     \"mappings\": {\n",
    "#         \"properties\": {\n",
    "#             \"text\": {\"type\": \"text\"},\n",
    "#             \"section\": {\"type\": \"text\"},\n",
    "#             \"question\": {\"type\": \"text\"},\n",
    "#             \"course\": {\"type\": \"keyword\"} \n",
    "#         }\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# es = Elasticsearch(\"http://localhost:9200\")\n",
    "# es.info()\n",
    "\n",
    "# index_name = \"faq_elasticsearch_data\"\n",
    "# response = es.indices.create(index=index_name, body=index_settings)\n",
    "\n",
    "# print(response)\n",
    "\n",
    "# for doc in tqdm(documents):\n",
    "#     es.index(index=\"faq_elasticsearch_data\", document=doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initiate Elasticsearch connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch(\"http://localhost:9200\")\n",
    "es.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### retrieve docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def retrieve_documents(query, index_name=\"faq_elasticsearch_data\", max_results=5, filter: dict = None):\n",
    "#     es = Elasticsearch(\"http://localhost:9200\")\n",
    "    \n",
    "#     search_query = {\n",
    "#         \"size\": max_results,\n",
    "#         \"query\": {\n",
    "#             \"bool\": {\n",
    "#                 \"must\": {\n",
    "#                     \"multi_match\": {\n",
    "#                         \"query\": query,\n",
    "#                         \"fields\": [\"question^4\", \"text\"],\n",
    "#                         \"type\": \"best_fields\"\n",
    "#                     }\n",
    "#                 },\n",
    "#                 \"filter\": filter\n",
    "#             }\n",
    "#         }\n",
    "#     }\n",
    "#     # print(search_query)\n",
    "#     response = es.search(index=index_name, body=search_query)\n",
    "#     documents = [hit['_source'] for hit in response['hits']['hits']]\n",
    "#     scores = [hit['_score'] for hit in response['hits']['hits']]\n",
    "#     return documents, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_question = \"How do I execute a command in a running docker container?\"\n",
    "# filter = {\n",
    "#     \"term\": {\n",
    "#         \"course\": \"machine-learning-zoomcamp\"\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# # response = retrieve_documents(query=sample_question, max_results=3)#, filter=filter)\n",
    "# # print(response)\n",
    "# response, scores = retrieve_documents(query=sample_question, max_results=3, filter=filter)\n",
    "# # response, scores = retrieve_documents(query=sample_question, max_results=5)#, filter=filter)\n",
    "# print(f\"scores: {scores}\\n\")\n",
    "# for doc in response:\n",
    "#     print(f\"course: {doc['course']}\")\n",
    "#     print(f\"section: {doc['section']}\")\n",
    "#     print(f\"question: {doc['question']}\")\n",
    "#     print(f\"answer: {doc['text'][:60]}...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_documents_v2(query=None, index_name=\"faq_elasticsearch_data\", max_results=5, filter=None):\n",
    "    es = Elasticsearch(\"http://localhost:9200\")\n",
    "    \n",
    "    search_query = {\n",
    "        \"size\": max_results,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": [],\n",
    "                \"filter\": []\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    if query:\n",
    "        search_query[\"query\"][\"bool\"][\"must\"].append({\n",
    "            \"multi_match\": {\n",
    "                \"query\": query,\n",
    "                \"fields\": [\"question^4\", \"text\"],\n",
    "                \"type\": \"best_fields\"\n",
    "            }\n",
    "        })\n",
    "    else:\n",
    "        search_query[\"query\"][\"bool\"][\"must\"].append({\"match_all\": {}})\n",
    "    \n",
    "    if filter:\n",
    "        for key, value in filter.items():\n",
    "            search_query[\"query\"][\"bool\"][\"filter\"].append({\n",
    "                \"term\": {f\"{key}.keyword\": value}\n",
    "            })\n",
    "    \n",
    "    response = es.search(index=index_name, body=search_query)\n",
    "    documents = [hit['_source'] for hit in response['hits']['hits']]\n",
    "    scores = [hit['_score'] for hit in response['hits']['hits']]\n",
    "    return documents, scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_question = \"How do I execute a command in a running docker container?\"\n",
    "filter = {\n",
    "        \"course\": \"machine-learning-zoomcamp\"\n",
    "}\n",
    "\n",
    "response, scores = retrieve_documents_v2(query=sample_question, max_results=3, filter=filter)\n",
    "\n",
    "print(f\"scores: {scores}\\n\")\n",
    "for doc in response:\n",
    "    print(f\"course: {doc['course']}\")\n",
    "    print(f\"section: {doc['section']}\")\n",
    "    print(f\"question: {doc['question']}\")\n",
    "    print(f\"answer: {doc['text'][:60]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build prompt\n",
    "* Q5: length of prompt\n",
    "* Q6: number of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(question: str, context_docs: list) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    You're a course teaching assistant. Answer the user QUESTION based on CONTEXT - the documents retrieved from our FAQ database. \n",
    "    Only use the facts from the CONTEXT. If the CONTEXT doesn't contan the answer, return \"NONE\"\n",
    "\n",
    "    QUESTION: {question}\n",
    "\n",
    "    CONTEXT:\n",
    "    {build_context(context_docs)}\n",
    "    \"\"\".strip()\n",
    "\n",
    "    return prompt\n",
    "\n",
    "def build_context(context_docs: list) -> str:\n",
    "    context_template = \"\"\"\n",
    "    Section: {section}\n",
    "    Question: {question}\n",
    "    Answer: {text}\n",
    "    \"\"\".strip()\n",
    "\n",
    "    context_result = \"\"\n",
    "\n",
    "    for doc in context_docs:\n",
    "        doc_str = context_template.format(**doc)\n",
    "        context_result += (\"\\n\\n\" + doc_str)\n",
    "\n",
    "    return context_result.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = build_prompt(sample_question, response)\n",
    "print(f\"length of prompt: {len(prompt)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "print(f\"number of tokens: {len(encoding.encode(prompt))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_openai_answer(prompt: str) -> str:\n",
    "    client = OpenAI()\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    ")\n",
    "    answer = response.choices[0].message.content\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa_bot(question: str, course: str = None) -> str:\n",
    "    if course:\n",
    "        filter = {\n",
    "            \"term\": {\n",
    "                \"course\": course\n",
    "            }\n",
    "        }\n",
    "    else:\n",
    "        filter = None\n",
    "\n",
    "    response = retrieve_documents(query=question, max_results=3, filter=filter)\n",
    "    prompt = build_prompt(question, response)\n",
    "    answer = get_openai_answer(prompt)\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## demo\n",
    "* bonus 1: generating the answer\n",
    "* bonus 2: calculate costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_question = \"How do I execute a command in a running docker container?\"\n",
    "course = 'machine-learning-zoomcamp'\n",
    "\n",
    "answer = qa_bot(question=sample_question, course=course)\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tokens_count = 150\n",
    "output_tokens_count = 250\n",
    "\n",
    "input_cost_per_1k_tokens = 0.005\n",
    "output_cost_per_1k_tokens = 0.015\n",
    "\n",
    "num_of_requests = 1000\n",
    "\n",
    "input_cost = input_tokens_count * (input_cost_per_1k_tokens/1000)\n",
    "output_cost = output_tokens_count * (output_cost_per_1k_tokens/1000)\n",
    "\n",
    "total_cost = (input_cost + output_cost) * num_of_requests\n",
    "print(f\"total cost: ${total_cost:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-zoomcamp-Z3WHHSAp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
